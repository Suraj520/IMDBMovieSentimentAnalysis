{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Movie Sentiment Analysis",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "kY1QCNdHxKyO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 8
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "4e46a52c-e9f0-4d93-95c8-c07832688ba7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1517043977826,
          "user_tz": -330,
          "elapsed": 6088,
          "user": {
            "displayName": "Suraj",
            "photoUrl": "//lh5.googleusercontent.com/-n0XOqm4pzzY/AAAAAAAAAAI/AAAAAAAAGMk/QR2xoSjmXbk/s50-c-k-no/photo.jpg",
            "userId": "108764986987181223074"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#installing tflearn\n",
        "!pip install -U tflearn"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tflearn\n",
            "  Downloading tflearn-0.3.2.tar.gz (98kB)\n",
            "\u001b[K    100% |████████████████████████████████| 102kB 2.1MB/s \n",
            "\u001b[?25hCollecting Pillow (from tflearn)\n",
            "  Downloading Pillow-5.0.0-cp27-cp27mu-manylinux1_x86_64.whl (5.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.9MB 209kB/s \n",
            "\u001b[?25hRequirement already up-to-date: numpy in /usr/local/lib/python2.7/dist-packages (from tflearn)\n",
            "Requirement already up-to-date: six in /usr/local/lib/python2.7/dist-packages (from tflearn)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Running setup.py bdist_wheel for tflearn ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/fb/06/72/0478c938ca315c6fddcce8233b80ec91a115ce4496a27e8c90\n",
            "Successfully built tflearn\n",
            "Installing collected packages: Pillow, tflearn\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed Pillow-5.0.0 tflearn-0.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tY3ew0bEyD9_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Google drive authentication Code\n",
        "!pip install -U -q PyDrive\n",
        "import numpy as np\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5-d84JxzyJxl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# 1. Authenticate and create the PyDrive client.\n",
        "#auth.authenticate_user()\n",
        "#gauth = GoogleAuth()\n",
        "#gauth.credentials = GoogleCredentials.get_application_default()\n",
        "#drive = GoogleDrive(gauth)\n",
        "\n",
        "#our code already uses the embedded imdb dataset inside tflearn so we don't need to manually load the dataset\n",
        "# 2. Load a file by ID and create local file.\n",
        "#downloaded = drive.CreateFile({'id':'1v8RtfJ3JN7i4o7xHxtu-r_IRo-j7uwvh'}) # replace fileid with Id of file you want to access represented by long string in single quotes\n",
        "#downloaded.GetContentFile('data.csv') # now you can use export.csv share\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0TzLhY2NxPqO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "841c01d2-1840-4db2-be16-3d2b3fa73c67"
      },
      "cell_type": "code",
      "source": [
        "#importing libraries and dataset required to do so\n",
        "from __future__ import division, print_function, absolute_import\n",
        "import tflearn\n",
        "from tflearn.data_utils import to_categorical, pad_sequences\n",
        "from tflearn.datasets import imdb\n",
        "\n",
        "# IMDB Dataset loading\n",
        "train, test, _ = imdb.load_data(path='imdb.pkl', n_words=10000,\n",
        "                                valid_portion=0.1)\n",
        "#validation data prevents overfitting\n",
        "trainX, trainY = train\n",
        "testX, testY = test\n",
        "\n",
        "#Data preprocessing\n",
        "\n",
        "#sequence padding\n",
        "#converting words to vector by padding to zeros\n",
        "\n",
        "#to categorical are binary function with 1 or 0 for labels\n",
        "\n",
        "trainX = pad_sequences(trainX, maxlen=100, value=0.)\n",
        "testX = pad_sequences(testX, maxlen=100, value=0.)\n",
        "\n",
        "#converting the labels to categorical or binary vectors\n",
        "trainY= to_categorical(trainY, nb_classes =2)\n",
        "testY= to_categorical(testY, nb_classes =2)\n",
        "\n",
        "#network building\n",
        "#input layer  \n",
        "#specifying the input layer shape by setting batch size as first parameter set to None and word length to 100\n",
        "net = tflearn.input_data([None, 100])\n",
        "#2nd layer takes 10000 words and outputs 128\n",
        "net = tflearn.embedding(net,input_dim = 10000, output_dim =128)\n",
        "\n",
        "#feeding this output of 2nd layer to lstm layer which allows to network to remember data from beginning of sequences\n",
        "\n",
        "#applying dropout by randomlu turning on/off some connections in neural network\n",
        "net = tflearn.lstm(net,128,dropout =0.8)\n",
        "\n",
        "#passing this to a fully connected layer with softmax activation function \n",
        "#softmax take input values and squash them into output probability of 0 and 1\n",
        "net = tflearn.fully_connected(net,2, activation ='softmax')\n",
        "\n",
        "#last layer to regression\n",
        "\n",
        "#adam optimiser performs gradient descent and categorical cross entropy being our loss function\n",
        "\n",
        "net  =tflearn.regression(net,optimizer='adam', learning_rate=0.0001, loss='categorical_crossentropy')\n",
        "\n",
        "#training \n",
        "model = tflearn.DNN(net, tensorboard_verbose=0)\n",
        "model.fit(trainX, trainY, validation_set=(testX, testY), show_metric=True,\n",
        "          batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 2470  | total loss: \u001b[1m\u001b[32m0.26918\u001b[0m\u001b[0m | time: 26.076s\n",
            "\u001b[2K\r| Adam | epoch: 004 | loss: 0.26918 - acc: 0.8916 -- iter: 11456/22500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Pb5mCIiF2lHZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}